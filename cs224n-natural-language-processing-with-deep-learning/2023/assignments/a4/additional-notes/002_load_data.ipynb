{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils import read_corpus, Vocab, collate_fn\n",
    "\n",
    "# import torch\n",
    "# from torch.nn.utils.rnn import pad_sequence\n",
    "# def collate_fn(batch):\n",
    "#     src_sentences, tgt_sentences = zip(*batch)\n",
    "#     src_sentences = [torch.tensor(sent) for sent in src_sentences]\n",
    "#     tgt_sentences = [torch.tensor(sent) for sent in tgt_sentences]\n",
    "#     src_sentences = pad_sequence(src_sentences, batch_first=True)\n",
    "#     tgt_sentences = pad_sequence(tgt_sentences, batch_first=True)\n",
    "#     return src_sentences, tgt_sentences\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "shuffle = True\n",
    "\n",
    "data_path = Path(\"../code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_src = read_corpus(data_path.joinpath(\"zh_en_data\", \"train_debug.zh\"), data_path / \"src.model\")\n",
    "train_data_tgt = read_corpus(data_path.joinpath(\"zh_en_data\", \"train_debug.en\"), data_path / \"tgt.model\")\n",
    "\n",
    "valid_data_src = read_corpus(data_path.joinpath(\"zh_en_data\", \"dev.en\"), data_path / \"src.model\")\n",
    "valid_data_tgt = read_corpus(data_path.joinpath(\"zh_en_data\", \"dev.zh\"), data_path / \"tgt.model\")\n",
    "\n",
    "vocab = Vocab.load(data_path / \"vocab.json\")\n",
    "print(vocab)\n",
    "\n",
    "train_data_indices_src = vocab.src.words2indices(train_data_src)\n",
    "train_data_indices_tgt = vocab.tgt.words2indices(train_data_tgt)\n",
    "\n",
    "valid_data_indices_src = vocab.src.words2indices(valid_data_src)\n",
    "valid_data_indices_tgt = vocab.tgt.words2indices(valid_data_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = list(zip(train_data_indices_src, train_data_indices_tgt))\n",
    "valid_data = list(zip(valid_data_indices_src, valid_data_indices_tgt))\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn)\n",
    "\n",
    "src_sentences, tgt_sentences, _ = next(iter(train_loader))\n",
    "print(f\"src shape: {src_sentences.shape}, tgt shape: {tgt_sentences.shape}\")\n",
    "\n",
    "print(\"src and tgt sentences:\")\n",
    "for src_sent, tgt_sent in zip(src_sentences, tgt_sentences):\n",
    "    src_sent = \"\".join(vocab.src.indices2words(src_sent.tolist()))\n",
    "    tgt_sent = \"\".join(vocab.tgt.indices2words(tgt_sent.tolist()))\n",
    "    print(\"-\" * 100)\n",
    "    print(src_sent.replace(\"<pad>\", \"\").replace(\"▁\", \" \"))\n",
    "    print(tgt_sent.replace(\"<pad>\", \"\").replace(\"▁\", \" \").replace(\"</s>\", \"\").replace(\"<s>\", \"\"))\n",
    "    print(\"-\" * 100)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
