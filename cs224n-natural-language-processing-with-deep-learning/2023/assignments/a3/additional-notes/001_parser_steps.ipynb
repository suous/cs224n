{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import read_conll, Parser\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_path = Path(\"../code/data\")\n",
    "df = pd.DataFrame(read_conll(data_path.joinpath(\"train.conll\"), lowercase=True))[:1000]\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29b152dd778b85be"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "parser = Parser(df)\n",
    "parser.vectorize(*df[:2].to_dict(\"records\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d505908cfe600e05"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load word vectors from file\n",
    "word_vectors = {}\n",
    "for line in open(data_path.joinpath(\"en-cw.txt\")).readlines():\n",
    "    word, *embedding = line.strip().split()\n",
    "    word_vectors[word] = np.asarray(embedding, dtype=\"float32\")\n",
    "\n",
    "# Initialize embeddings matrix with random values\n",
    "embeddings_matrix = np.asarray(np.random.normal(0, 0.9, (parser.n_tokens, 50)), dtype=\"float32\")\n",
    "\n",
    "# Map each token to its corresponding embedding vector\n",
    "for token in parser.tok2id:\n",
    "    i = parser.tok2id[token]\n",
    "    if token in word_vectors:\n",
    "        embeddings_matrix[i] = word_vectors[token]\n",
    "    elif token.lower() in word_vectors:\n",
    "        embeddings_matrix[i] = word_vectors[token.lower()]\n",
    "\n",
    "sample_index = 11\n",
    "sub_samples = 6\n",
    "\n",
    "sample = {k: v[:sub_samples] for k, v in df.iloc[sample_index].to_dict().items() if isinstance(v, list)}\n",
    "dev_set = parser.vectorize(sample)\n",
    "\n",
    "sample = pd.DataFrame(df.iloc[sample_index, :4].to_list()).T[:sub_samples]\n",
    "sample.columns = [\"word\", \"pos\", \"head\", \"label\"]\n",
    "sample"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b7b71df15312ebd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_vector_df = pd.DataFrame(dev_set[0])\n",
    "sample_vector_df[\"w\"] = sample_vector_df.word.apply(parser.id2tok.get)\n",
    "sample_vector_df[\"p\"] = sample_vector_df.pos.apply(parser.id2tok.get)\n",
    "sample_vector_df[\"l\"] = sample_vector_df.label.apply(parser.id2tok.get)\n",
    "sample_vector_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd6d8d498b5bcd30"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "instances = parser.create_instances(*dev_set)\n",
    "print(\"number of instances:\", len(instances))\n",
    "for words, legal_labels, gold_t in instances:\n",
    "    print(\"legal labels:\", legal_labels)\n",
    "    print(\"gold transition:\", gold_t)\n",
    "    print([parser.id2tok.get(w) for w in words])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55b8b72c19fbd9d4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sentence = \" \".join(sample.word)\n",
    "print(f\"The steps for the sample: '{sentence}'\")\n",
    "pd.read_csv(\"create_instances_sample.csv\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6def4e970053e8bd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
